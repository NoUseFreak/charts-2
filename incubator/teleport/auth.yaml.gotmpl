## Teleport Auth chart configuration

{{- $authurl := (print "auth.portal." (requiredEnv "CLUSTER")) }}

extraArgs:
  ## enable debug
  # debug:

podAnnotations:
  iam.amazonaws.com/role: "{{ requiredEnv "CLUSTER" }}-teleport-auth"

service:
  annotations:
     external-dns.alpha.kubernetes.io/hostname: "{{ $authurl }}."

## teleport config file
config:
  teleport.yaml: |-
    # This section of the configuration file applies to all teleport services
    teleport:
      # nodename allows to assign an alternative name this node can be reached by
      # by default it's equal to hostname
      #nodename:

      # Data directory where Teleport keeps its data, like keys/users for
      # authentication (if using the default BoltDB back-end)
      data_dir: /var/lib/teleport

      # one-time invitation token used to join a cluster. it is not used on
      # subsequent starts
      auth_token: "{{ exec "./get-config.sh" (list "auth_token") | trim }}"

      # when running in multi-homed or NATed environments Teleport nodes need
      # to know which IP it will be reachable at by other nodes
      # advertise_ip:

      # Teleport throttles all connections to avoid abuse. These settings allow
      # you to adjust the default limits
      connection_limits:
        # Number of max. simultaneous connections from an IP
        max_connections: 1000
        # Number of max. simultaneous connected users/logins
        max_users: 100

      # Logging configuration. Possible output values are 'stdout', 'stderr' and
      # 'syslog'. Possible severity values are INFO, WARN and ERROR (default).
      log:
        output: stdout
        severity: INFO

      # Type of storage used for keys. You need to configure this to use etcd
      # backend if you want to run Teleport in HA configuration.
      storage:
        type: dynamodb
        audit_sessions_uri: s3://{{ requiredEnv "CLUSTER" }}-teleport
        audit_events_uri: dynamodb://{{ requiredEnv "CLUSTER" }}-teleport-events
        region: {{ requiredEnv "AWS_REGION" }}
        table_name: {{ requiredEnv "CLUSTER" }}-teleport-state

    # This section configures the 'auth service':
    auth_service:
      # Turns 'auth' role on. Default is 'yes'
      enabled: yes

      # defines the types and second factors the auth server supports
      authentication:
        # type can be local or oidc
        type: saml
        # second_factor can be off, otp, or u2f
        second_factor: otp

        # this section is only used if using u2f
        u2f:
          # app_id should point to the Web UI.
          app_id: https://0.0.0.0

          # facets should list all proxy servers.
          facets:
          - https://0.0.0.0
          - https://0.0.0.0:3080

      # IP and the port to bind to. Other Teleport nodes will be connecting to
      # this port (AKA "Auth API" or "Cluster API") to validate client
      # certificates
      listen_addr: 0.0.0.0:3025

      # The optional DNS name the auth server if located behind a load balancer.
      public_addr: {{ $authurl }}

      # Pre-defined tokens for adding new nodes to a cluster. Each token specifies
      # the role a new node will be allowed to assume. The more secure way to
      # add nodes is to use `ttl node add --ttl` command to generate auto-expiring
      # tokens.
      #
      # We recommend to use tools like `pwgen` to generate sufficiently random
      # tokens of 32+ byte length.
      tokens:
        - "node:{{ exec "./get-config.sh" (list "node_token") | trim }}"
        - "proxy:{{ exec "./get-config.sh" (list "proxy_token") | trim }}"
        - "auth:{{ exec "./get-config.sh" (list "auth_token") | trim }}"
        - "trusted_cluster:"

      # Optional "cluster name" is needed when configuring trust between multiple
      # auth servers. A cluster name is used as part of a signature in certificates
      # generated by this CA.
      #
      # By default an automatically generated GUID is used.
      #
      # IMPORTANT: if you change cluster_name, it will invalidate all generated
      # certificates and keys (may need to wipe out /var/lib/teleport directory)
      cluster_name: "{{ requiredEnv "CLUSTER" }}"

      # License file to start auth server with. Note that this setting is ignored
      # in open-source Teleport and is required only for Teleport Pro, Business
      # and Enterprise subscription plans.
      #
      # The path can be either absolute or relative to the configured `data_dir`
      # and should point to the license file obtained from Teleport Download Portal.
      #
      license_file: "/etc/teleport/license.pem"

  ## License file
  license.pem: |-
{{ exec "./get-config.sh" (list "license") | trim | indent 4 }}

bootstrap:
  enabled: true
  resources:

## Affinity for pod assignment
## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
affinity: {}

# Tolerations for pod assignment
# Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
tolerations: []
